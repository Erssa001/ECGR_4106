{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary class to handle mapping between words and numerical indices\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Initialize dictionaries for word to index and index to word mappings\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
    "        self.word_count = {}  # Keep track of word frequencies\n",
    "        self.n_words = 3  # Start counting from 3 to account for special tokens\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        # Add all words in a sentence to the vocabulary\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        # Add a word to the vocabulary\n",
    "        if word not in self.word2index:\n",
    "            # Assign a new index to the word and update mappings\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # Increment word count if the word already exists in the vocabulary\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "def tokenize_and_pad(sentences, vocab):\n",
    "    # Calculate the maximum sentence length for padding\n",
    "    max_length = max(len(sentence.split(' ')) for sentence in sentences) + 2  # +2 for SOS and EOS tokens\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Convert each sentence to a list of indices, adding SOS and EOS tokens\n",
    "        tokens = [vocab.word2index[\"<SOS>\"]] + [vocab.word2index[word] for word in sentence.split(' ')] + [vocab.word2index[\"<EOS>\"]]\n",
    "        # Pad sentences to the maximum length\n",
    "        padded_tokens = tokens + [vocab.word2index[\"<PAD>\"]] * (max_length - len(tokens))\n",
    "        tokenized_sentences.append(padded_tokens)\n",
    "    return torch.tensor(tokenized_sentences, dtype=torch.long)\n",
    "\n",
    "# Custom Dataset class for English to French sentences\n",
    "class EngFrDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.eng_vocab = Vocabulary()\n",
    "        self.fr_vocab = Vocabulary()\n",
    "        self.pairs = []\n",
    "\n",
    "        # Process each English-French pair\n",
    "        for eng, fr in pairs:\n",
    "            self.eng_vocab.add_sentence(eng)\n",
    "            self.fr_vocab.add_sentence(fr)\n",
    "            self.pairs.append((eng, fr))\n",
    "\n",
    "        # Separate English and French sentences\n",
    "        self.eng_sentences = [pair[0] for pair in self.pairs]\n",
    "        self.fr_sentences = [pair[1] for pair in self.pairs]\n",
    "        \n",
    "        # Tokenize and pad sentences\n",
    "        self.eng_tokens = tokenize_and_pad(self.eng_sentences, self.eng_vocab)\n",
    "        self.fr_tokens = tokenize_and_pad(self.fr_sentences, self.fr_vocab)\n",
    "\n",
    "        # Define the embedding layers for English and French\n",
    "        self.eng_embedding = torch.nn.Embedding(self.eng_vocab.n_words, 100)  # Embedding size = 100\n",
    "        self.fr_embedding = torch.nn.Embedding(self.fr_vocab.n_words, 100)    # Embedding size = 100\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of sentence pairs\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the tokenized and padded sentences by index\n",
    "        eng_tokens = self.eng_tokens[idx]\n",
    "        fr_tokens = self.fr_tokens[idx]\n",
    "        # Lookup embeddings for the tokenized sentences\n",
    "        eng_emb = self.eng_embedding(eng_tokens)\n",
    "        fr_emb = self.fr_embedding(fr_tokens)\n",
    "        return eng_tokens, fr_tokens, eng_emb, fr_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Sample dataset of English-French sentence pairs\n",
    "# english_to_french = [\n",
    "#     (\"I am cold\", \"J'ai froid\"),\n",
    "#     (\"You are tired\", \"Tu es fatigué\"),\n",
    "#     (\"He is hungry\", \"Il a faim\"),\n",
    "#     (\"She is happy\", \"Elle est heureuse\"),\n",
    "#     (\"We are friends\", \"Nous sommes amis\"),\n",
    "#     (\"They are students\", \"Ils sont étudiants\"),\n",
    "#     (\"The cat is sleeping\", \"Le chat dort\"),\n",
    "#     (\"The sun is shining\", \"Le soleil brille\"),\n",
    "#     (\"We love music\", \"Nous aimons la musique\"),\n",
    "#     (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
    "#     (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
    "#     (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
    "#     (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
    "#     (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
    "#     (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
    "#     (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
    "#     (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
    "#     (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
    "#     (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
    "#     (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
    "#     (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
    "#     (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
    "#     (\"The book is on the table\", \"Le livre est sur la table\"),\n",
    "#     (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
    "#     (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
    "#     (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
    "#     (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
    "#     (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
    "#     (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
    "#     (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "#     (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
    "#     (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
    "#     (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
    "#     (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
    "#     (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
    "#     (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
    "#     (\"He paints landscapes\", \"Il peint des paysages\"),\n",
    "#     (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
    "#     (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
    "#     (\"She runs in the park\", \"Elle court dans le parc\"),\n",
    "#     (\"We travel by train\", \"Nous voyageons en train\"),\n",
    "#     (\"He writes a letter\", \"Il écrit une lettre\"),\n",
    "#     (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
    "#     (\"The baby cries\", \"Le bébé pleure\"),\n",
    "#     (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
    "#     (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
    "#     (\"He fixes the car\", \"Il répare la voiture\"),\n",
    "#     (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
    "#     (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
    "#     (\"She dances at the party\", \"Elle danse à la fête\"),\n",
    "#     (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
    "#     (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
    "#     (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
    "#     (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
    "#     (\"She sings a song\", \"Elle chante une chanson\"),\n",
    "#     (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
    "#     (\"He sleeps deeply\", \"Il dort profondément\"),\n",
    "#     (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
    "#     (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
    "#     (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
    "#     (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
    "#     (\"He waits for the bus\", \"Il attend le bus\"),\n",
    "#     (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
    "#     (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
    "#     (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
    "#     (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
    "#     (\"He studies history\", \"Il étudie l'histoire\"),\n",
    "#     (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
    "#     (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
    "#     (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
    "#     (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
    "#     (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
    "#     (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
    "#     (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
    "#     (\"She paints a picture\", \"Elle peint un tableau\"),\n",
    "#     (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
    "#     (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample dataset of english-french sentence pairs without capital letters\n",
    "english_to_french = [\n",
    "    (\"i am cold\", \"j'ai froid\"),\n",
    "    (\"you are tired\", \"tu es fatigué\"),\n",
    "    (\"he is hungry\", \"il a faim\"),\n",
    "    (\"she is happy\", \"elle est heureuse\"),\n",
    "    (\"we are friends\", \"nous sommes amis\"),\n",
    "    (\"they are students\", \"ils sont étudiants\"),\n",
    "    (\"the cat is sleeping\", \"le chat dort\"),\n",
    "    (\"the sun is shining\", \"le soleil brille\"),\n",
    "    (\"we love music\", \"nous aimons la musique\"),\n",
    "    (\"she speaks french fluently\", \"elle parle français couramment\"),\n",
    "    (\"he enjoys reading books\", \"il aime lire des livres\"),\n",
    "    (\"they play soccer every weekend\", \"ils jouent au football chaque week-end\"),\n",
    "    (\"the movie starts at 7 pm\", \"le film commence à 19 heures\"),\n",
    "    (\"she wears a red dress\", \"elle porte une robe rouge\"),\n",
    "    (\"we cook dinner together\", \"nous cuisinons le dîner ensemble\"),\n",
    "    (\"he drives a blue car\", \"il conduit une voiture bleue\"),\n",
    "    (\"they visit museums often\", \"ils visitent souvent des musées\"),\n",
    "    (\"the restaurant serves delicious food\", \"le restaurant sert une délicieuse cuisine\"),\n",
    "    (\"she studies mathematics at university\", \"elle étudie les mathématiques à l'université\"),\n",
    "    (\"we watch movies on fridays\", \"nous regardons des films le vendredi\"),\n",
    "    (\"he listens to music while jogging\", \"il écoute de la musique en faisant du jogging\"),\n",
    "    (\"they travel around the world\", \"ils voyagent autour du monde\"),\n",
    "    (\"the book is on the table\", \"le livre est sur la table\"),\n",
    "    (\"she dances gracefully\", \"elle danse avec grâce\"),\n",
    "    (\"we celebrate birthdays with cake\", \"nous célébrons les anniversaires avec un gâteau\"),\n",
    "    (\"he works hard every day\", \"il travaille dur tous les jours\"),\n",
    "    (\"they speak different languages\", \"ils parlent différentes langues\"),\n",
    "    (\"the flowers bloom in spring\", \"les fleurs fleurissent au printemps\"),\n",
    "    (\"she writes poetry in her free time\", \"elle écrit de la poésie pendant son temps libre\"),\n",
    "    (\"we learn something new every day\", \"nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "    (\"the dog barks loudly\", \"le chien aboie bruyamment\"),\n",
    "    (\"he sings beautifully\", \"il chante magnifiquement\"),\n",
    "    (\"they swim in the pool\", \"ils nagent dans la piscine\"),\n",
    "    (\"the birds chirp in the morning\", \"les oiseaux gazouillent le matin\"),\n",
    "    (\"she teaches english at school\", \"elle enseigne l'anglais à l'école\"),\n",
    "    (\"we eat breakfast together\", \"nous prenons le petit déjeuner ensemble\"),\n",
    "    (\"he paints landscapes\", \"il peint des paysages\"),\n",
    "    (\"they laugh at the joke\", \"ils rient de la blague\"),\n",
    "    (\"the clock ticks loudly\", \"l'horloge tic-tac bruyamment\"),\n",
    "    (\"she runs in the park\", \"elle court dans le parc\"),\n",
    "    (\"we travel by train\", \"nous voyageons en train\"),\n",
    "    (\"he writes a letter\", \"il écrit une lettre\"),\n",
    "    (\"they read books at the library\", \"ils lisent des livres à la bibliothèque\"),\n",
    "    (\"the baby cries\", \"le bébé pleure\"),\n",
    "    (\"she studies hard for exams\", \"elle étudie dur pour les examens\"),\n",
    "    (\"we plant flowers in the garden\", \"nous plantons des fleurs dans le jardin\"),\n",
    "    (\"he fixes the car\", \"il répare la voiture\"),\n",
    "    (\"they drink coffee in the morning\", \"ils boivent du café le matin\"),\n",
    "    (\"the sun sets in the evening\", \"le soleil se couche le soir\"),\n",
    "    (\"she dances at the party\", \"elle danse à la fête\"),\n",
    "    (\"we play music at the concert\", \"nous jouons de la musique au concert\"),\n",
    "    (\"he cooks dinner for his family\", \"il cuisine le dîner pour sa famille\"),\n",
    "    (\"they study french grammar\", \"ils étudient la grammaire française\"),\n",
    "    (\"the rain falls gently\", \"la pluie tombe doucement\"),\n",
    "    (\"she sings a song\", \"elle chante une chanson\"),\n",
    "    (\"we watch a movie together\", \"nous regardons un film ensemble\"),\n",
    "    (\"he sleeps deeply\", \"il dort profondément\"),\n",
    "    (\"they travel to paris\", \"ils voyagent à paris\"),\n",
    "    (\"the children play in the park\", \"les enfants jouent dans le parc\"),\n",
    "    (\"the walks along the beach\", \"elle se promène le long de la plage\"),\n",
    "    (\"we talk on the phone\", \"nous parlons au téléphone\"),\n",
    "    (\"he waits for the bus\", \"il attend le bus\"),\n",
    "    (\"they visit the eiffel tower\", \"ils visitent la tour eiffel\"),\n",
    "    (\"the stars twinkle at night\", \"les étoiles scintillent la nuit\"),\n",
    "    (\"she dreams of flying\", \"elle rêve de voler\"),\n",
    "    (\"we work in the office\", \"nous travaillons au bureau\"),\n",
    "    (\"he studies history\", \"il étudie l'histoire\"),\n",
    "    (\"they listen to the radio\", \"ils écoutent la radio\"),\n",
    "    (\"the wind blows gently\", \"le vent souffle doucement\"),\n",
    "    (\"she swims in the ocean\", \"elle nage dans l'océan\"),\n",
    "    (\"we dance at the wedding\", \"nous dansons au mariage\"),\n",
    "    (\"he climbs the mountain\", \"il gravit la montagne\"),\n",
    "    (\"they hike in the forest\", \"ils font de la randonnée dans la forêt\"),\n",
    "    (\"the cat meows loudly\", \"le chat miaule bruyamment\"),\n",
    "    (\"she paints a picture\", \"elle peint un tableau\"),\n",
    "    (\"we build a sandcastle\", \"nous construisons un château de sable\"),\n",
    "    (\"he sings in the choir\", \"il chante dans le chœur\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test sets\n",
    "english_to_french_train, english_to_french_test = train_test_split(english_to_french, test_size=0.3, random_state=42)\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "# Initialize training dataset and DataLoader\n",
    "train_dataset = EngFrDataset(english_to_french_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize test dataset and DataLoader\n",
    "test_dataset = EngFrDataset(english_to_french_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize full dataset\n",
    "engFrDataset = EngFrDataset(english_to_french)\n",
    "train_loader= DataLoader(engFrDataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model based on repo codes (predicted only random)\n",
    "# # Positional Encoding\n",
    "# class PositionalEncoding(nn.Module):\n",
    "#     def __init__(self, d_model, max_len=5000):\n",
    "#         super(PositionalEncoding, self).__init__()\n",
    "#         self.encoding = torch.zeros(max_len, d_model).to(device)\n",
    "#         position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1).to(device)\n",
    "#         div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model)).to(device)\n",
    "#         self.encoding[:, 0::2] = torch.sin(position * div_term).to(device)\n",
    "#         self.encoding[:, 1::2] = torch.cos(position * div_term).to(device)\n",
    "#         self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x + self.encoding[:, :x.size(1)].detach()\n",
    "\n",
    "# # Define the Transformer model\n",
    "# class Transformer(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, d_model=100, nhead=2, num_encoder_layers=4, num_decoder_layers=4):\n",
    "#         super(Transformer, self).__init__()\n",
    "        \n",
    "#         self.pos_encoder = PositionalEncoding(d_model)\n",
    "#         self.transformer_encoder = nn.TransformerEncoder(\n",
    "#             nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
    "#             num_layers=num_encoder_layers\n",
    "#         )\n",
    "#         self.transformer_decoder = nn.TransformerDecoder(\n",
    "#             nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead),\n",
    "#             num_layers=num_decoder_layers\n",
    "#         )\n",
    "        \n",
    "#         self.linear = nn.Linear(d_model, output_dim)\n",
    "\n",
    "#     def forward(self, src, tgt):\n",
    "#         src = self.pos_encoder(src.permute(1, 0, 2))  # Change the dimension for Transformer input\n",
    "#         tgt = self.pos_encoder(tgt.permute(1, 0, 2))  # Change the dimension for Transformer input\n",
    "#         # print(f\"Source: {src}\")\n",
    "#         # print(f\"Target: {tgt}\")\n",
    "#         memory = self.transformer_encoder(src)\n",
    "#         output = self.transformer_decoder(tgt, memory)\n",
    "#         output = self.linear(output)\n",
    "#         # print(f\"Output: {output}\")\n",
    "#         return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pulled from https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1).to(device)\n",
    "        output = torch.matmul(attn_probs, V).to(device)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model).to(device)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1).to(device)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float().to(device) * -(math.log(10000.0) / d_model)).to(device)\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term).to(device)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term).to(device)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "class TransformerProf(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(TransformerProf, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length).to(device), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = engFrDataset.eng_vocab.n_words\n",
    "tgt_vocab_size = engFrDataset.fr_vocab.n_words\n",
    "d_model = 1024\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 11\n",
    "dropout = 0.15\n",
    "model = TransformerProf(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)#, betas=(0.9, 0.98), eps=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 1.3989180326461792, Val Loss: 4.339879989624023, Val Accuracy: 0.23776223776223776\n",
      "Epoch 20, Train Loss: 0.10658690830071767, Val Loss: 4.900830268859863, Val Accuracy: 0.3146853146853147\n",
      "Epoch 30, Train Loss: 0.03141459760566553, Val Loss: 5.535618305206299, Val Accuracy: 0.2937062937062937\n",
      "Epoch 40, Train Loss: 0.014569288119673729, Val Loss: 5.7225117683410645, Val Accuracy: 0.2867132867132867\n",
      "Epoch 50, Train Loss: 0.01029915145287911, Val Loss: 5.911131858825684, Val Accuracy: 0.2937062937062937\n",
      "Epoch 60, Train Loss: 0.008675736685593924, Val Loss: 5.986867427825928, Val Accuracy: 0.2937062937062937\n",
      "Epoch 70, Train Loss: 0.006598004760841529, Val Loss: 6.089540004730225, Val Accuracy: 0.2937062937062937\n",
      "Epoch 80, Train Loss: 0.005560614479084809, Val Loss: 6.173830986022949, Val Accuracy: 0.2937062937062937\n",
      "Epoch 90, Train Loss: 0.00482232046003143, Val Loss: 6.267244815826416, Val Accuracy: 0.2937062937062937\n",
      "Epoch 100, Train Loss: 0.003974670389046271, Val Loss: 6.288514137268066, Val Accuracy: 0.2937062937062937\n",
      "Epoch 110, Train Loss: 0.0034992292833824954, Val Loss: 6.330619812011719, Val Accuracy: 0.3006993006993007\n",
      "Epoch 120, Train Loss: 0.0029017794877290726, Val Loss: 6.392031669616699, Val Accuracy: 0.2937062937062937\n",
      "Epoch 130, Train Loss: 0.0027757325830558934, Val Loss: 6.47190523147583, Val Accuracy: 0.2937062937062937\n",
      "Epoch 140, Train Loss: 0.002579732099547982, Val Loss: 6.547147274017334, Val Accuracy: 0.2937062937062937\n",
      "Epoch 150, Train Loss: 0.002269426050285498, Val Loss: 6.596752643585205, Val Accuracy: 0.2937062937062937\n",
      "Epoch 160, Train Loss: 0.001956148616348704, Val Loss: 6.598228454589844, Val Accuracy: 0.2937062937062937\n",
      "Epoch 170, Train Loss: 0.0018045073763156931, Val Loss: 6.615758419036865, Val Accuracy: 0.3006993006993007\n",
      "Epoch 180, Train Loss: 0.0017005989793688059, Val Loss: 6.656121253967285, Val Accuracy: 0.2937062937062937\n",
      "Epoch 190, Train Loss: 0.0015521392924711108, Val Loss: 6.728606700897217, Val Accuracy: 0.2937062937062937\n",
      "Epoch 200, Train Loss: 0.001416980482948323, Val Loss: 6.7786455154418945, Val Accuracy: 0.2937062937062937\n",
      "Epoch 210, Train Loss: 0.0013102653125921886, Val Loss: 6.830864906311035, Val Accuracy: 0.2937062937062937\n",
      "Epoch 220, Train Loss: 0.0012065393772597115, Val Loss: 6.842756271362305, Val Accuracy: 0.2937062937062937\n",
      "Epoch 230, Train Loss: 0.0011759867193177342, Val Loss: 6.859318256378174, Val Accuracy: 0.2937062937062937\n",
      "Epoch 240, Train Loss: 0.001069975143764168, Val Loss: 6.887199401855469, Val Accuracy: 0.2937062937062937\n",
      "Epoch 250, Train Loss: 0.001037542747023205, Val Loss: 6.935007572174072, Val Accuracy: 0.2937062937062937\n",
      "Epoch 260, Train Loss: 0.0009252252445245782, Val Loss: 6.955600261688232, Val Accuracy: 0.2937062937062937\n",
      "Epoch 270, Train Loss: 0.0009538249384301404, Val Loss: 6.959034442901611, Val Accuracy: 0.2937062937062937\n",
      "Epoch 280, Train Loss: 0.000859345484059304, Val Loss: 7.003754615783691, Val Accuracy: 0.2937062937062937\n",
      "Epoch 290, Train Loss: 0.0008043483248911798, Val Loss: 7.010843276977539, Val Accuracy: 0.2937062937062937\n",
      "Epoch 300, Train Loss: 0.0007860215264372528, Val Loss: 7.072768211364746, Val Accuracy: 0.2937062937062937\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for eng_tokens, fr_tokens, eng_emb, fr_emb in train_dataloader:\n",
    "        eng_tokens, fr_tokens = eng_tokens.to(device), fr_tokens.to(device)\n",
    "        eng_emb, fr_emb = eng_emb.to(device), fr_emb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(eng_tokens, fr_tokens[:, :-1]) \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        fr_tokens_target = fr_tokens[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, fr_tokens_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate correct predictions\n",
    "        predicted = output.argmax(dim=1)\n",
    "        correct = (predicted == fr_tokens_target).sum().item()\n",
    "\n",
    "        # Number of non-padding tokens\n",
    "        non_pad_tokens = (fr_tokens_target != 0).sum().item()\n",
    "        \n",
    "        # Accumulate correct predictions and total tokens (excluding padding tokens)\n",
    "        total_correct += correct\n",
    "        total_tokens += non_pad_tokens\n",
    "    \n",
    "    # Calculate training accuracy and loss\n",
    "    train_accuracy = (total_correct / total_tokens)\n",
    "    train_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    if ((epoch+1) % 10 == 0):\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_tokens = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for eng_tokens, fr_tokens, eng_emb, fr_emb in test_dataloader:\n",
    "                eng_tokens, fr_tokens = eng_tokens.to(device), fr_tokens.to(device)\n",
    "                eng_emb, fr_emb = eng_emb.to(device), fr_emb.to(device)\n",
    "                output = model(eng_tokens, fr_tokens[:, :-1])\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output.contiguous().view(-1, output_dim)\n",
    "                fr_tokens_target = fr_tokens[:, 1:].contiguous().view(-1)\n",
    "                loss = criterion(output, fr_tokens_target)\n",
    "\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Calculate correct predictions\n",
    "                predicted = output.argmax(dim=1)\n",
    "                correct = (predicted == fr_tokens_target).sum().item()\n",
    "\n",
    "                # Number of non-padding tokens\n",
    "                non_pad_tokens = (fr_tokens_target != 0).sum().item()\n",
    "\n",
    "                # Accumulate correct predictions and total tokens (excluding padding tokens)\n",
    "                total_val_correct += correct\n",
    "                total_val_tokens += non_pad_tokens\n",
    "\n",
    "        # Calculate validation accuracy and loss\n",
    "        val_accuracy = (total_val_correct / total_val_tokens)\n",
    "        val_loss = total_val_loss / len(test_dataloader)\n",
    "\n",
    "        # Print training and validation metrics\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: ['we', 'plant', 'flowers', 'in', 'the', 'garden', '<EOS>']\n",
      "Target Sentence: ['nous', 'plantons', 'des', 'fleurs', 'dans', 'le', 'jardin', '<EOS>']\n",
      "Predicted French Sentence: ['nous', 'froid', 'fleurs', 'livres', 'dans']\n"
     ]
    }
   ],
   "source": [
    "# Training loop (unchanged)\n",
    "\n",
    "# After the training loop\n",
    "# Perform inference on a validation sentence\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Choose a random validation sentence\n",
    "    idx = random.randint(0, len(test_dataset) - 1)\n",
    "    eng_tokens, fr_tokens, eng_emb, fr_emb = test_dataset[idx]\n",
    "    eng_tokens, fr_tokens = eng_tokens.unsqueeze(0).to(device), fr_tokens.unsqueeze(0).to(device)\n",
    "    eng_emb, fr_emb = eng_emb.unsqueeze(0).to(device), fr_emb.unsqueeze(0).to(device)\n",
    "\n",
    "    # Run inference\n",
    "    output = model(eng_tokens, fr_tokens[:, :-1])\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output.view(-1, output_dim)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Convert target indices to French words\n",
    "    input_sentence = [test_dataset.eng_vocab.index2word[idx.item()] for idx in eng_tokens.squeeze(0)]\n",
    "    # Remove padding and SOS token\n",
    "    input_sentence = [word for word in input_sentence if word not in [\"<PAD>\", '<SOS>']]\n",
    "\n",
    "    # Convert predicted indices to French words\n",
    "    predicted_sentence = [test_dataset.fr_vocab.index2word[idx.item()] for idx in predicted]\n",
    "    # Remove padding and EOS token\n",
    "    predicted_sentence = [word for word in predicted_sentence if word not in [\"<PAD>\", \"<EOS>\"]]\n",
    "\n",
    "    # Convert target indices to French words\n",
    "    target_sentence = [test_dataset.fr_vocab.index2word[idx.item()] for idx in fr_tokens.squeeze(0)]\n",
    "    # Remove padding and SOS token\n",
    "    target_sentence = [word for word in target_sentence if word not in [\"<PAD>\", '<SOS>']]\n",
    "\n",
    "    # Print the original English sentence, target French sentence, and predicted French sentence\n",
    "    print(\"Input Sentence:\", input_sentence)\n",
    "    print(\"Target Sentence:\", target_sentence)\n",
    "    print(\"Predicted French Sentence:\", predicted_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence: ['we', 'plant', 'flowers', 'in', 'the', 'garden', '<EOS>']\n",
      "Target Sentence: ['nous', 'plantons', 'des', 'fleurs', 'dans', 'le', 'jardin', '<EOS>']\n",
      "Predicted French Sentence: ['nous', 'froid', 'fleurs', 'livres', 'dans']\n"
     ]
    }
   ],
   "source": [
    "# Training loop (unchanged)\n",
    "\n",
    "# After the training loop\n",
    "# Perform inference on a validation sentence\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Choose a random validation sentence\n",
    "    idx = random.randint(0, len(test_dataset) - 1)\n",
    "    eng_tokens, fr_tokens, eng_emb, fr_emb = test_dataset[idx]\n",
    "    eng_tokens, fr_tokens = eng_tokens.unsqueeze(0).to(device), fr_tokens.unsqueeze(0).to(device)\n",
    "    eng_emb, fr_emb = eng_emb.unsqueeze(0).to(device), fr_emb.unsqueeze(0).to(device)\n",
    "\n",
    "    # Run inference\n",
    "    output = model(eng_tokens, fr_tokens[:, :-1])\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output.view(-1, output_dim)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Convert target indices to French words\n",
    "    input_sentence = [test_dataset.eng_vocab.index2word[idx.item()] for idx in eng_tokens.squeeze(0)]\n",
    "    # Remove padding and SOS token\n",
    "    input_sentence = [word for word in input_sentence if word not in [\"<PAD>\", '<SOS>']]\n",
    "\n",
    "    # Convert predicted indices to French words\n",
    "    predicted_sentence = [test_dataset.fr_vocab.index2word[idx.item()] for idx in predicted]\n",
    "    # Remove padding and EOS token\n",
    "    predicted_sentence = [word for word in predicted_sentence if word not in [\"<PAD>\", \"<EOS>\"]]\n",
    "\n",
    "    # Convert target indices to French words\n",
    "    target_sentence = [test_dataset.fr_vocab.index2word[idx.item()] for idx in fr_tokens.squeeze(0)]\n",
    "    # Remove padding and SOS token\n",
    "    target_sentence = [word for word in target_sentence if word not in [\"<PAD>\", '<SOS>']]\n",
    "\n",
    "    # Print the original English sentence, target French sentence, and predicted French sentence\n",
    "    print(\"Input Sentence:\", input_sentence)\n",
    "    print(\"Target Sentence:\", target_sentence)\n",
    "    print(\"Predicted French Sentence:\", predicted_sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
